# Отчет Хаккатон Wildberries Фрод Детекция (определение блокировки стока)

## 1. Цель проекта

Проект направлен на создание модели для детекции фродовых (мошеннических) действий пользователей на платформе Wildberries где пользователи делают заказы выбивая склад конкурента. Целевой переменной является `target`, где 1 означает необходимость блокировки пользователя, а 0 - отсутствие такой необходимости.

## 2. Данные и библиотеки

-   **Библиотеки:**
    -   Стандартные: `pandas`, `numpy`, `matplotlib`, `seaborn`, `joblib`.
    *   Для машинного обучения: `sklearn` (предобработка, модели, метрики, пайплайны), `imblearn` (для работы с несбалансированными данными, в частности `SMOTE` и пайплайны).
-   **Данные:**
    -   Загрузка тренировочного (`df_train.csv`) и тестового (`df_test.csv`) датасетов с Google Drive с помощью утилиты `gdown`.
-   **Воспроизводимость:**
    -   Установлен `SEED = 42` для `random` и `numpy` для обеспечения воспроизводимости результатов.

## 3. Вспомогательные функции и классы

Были определены следующие пользовательские классы и функции:

-   **`MultiplyColumns(BaseEstimator, TransformerMixin)`:** Класс для создания новых признаков путем перемножения существующих колонок.
-   **`DivideColumns(BaseEstimator, TransformerMixin)`:** Класс для создания новых признаков путем деления одних колонок на другие, с обработкой деления на ноль (заменяет результат на `np.nan`).
-   **`get_preds_and_metric(model, X, y)`:** Функция для получения предсказаний модели и расчета F1-меры (binary).
-   **`grid_and_print(...)`:** Функция для выполнения `GridSearchCV` (поиска по сетке), вывода лучших параметров, F1-меры на обучающей и тестовой (валидационной) выборках, а также построения матрицы ошибок.
-   **`get_pipeline_results(...)`:** Функция для обучения пайплайна с заданными параметрами, вывода F1-меры на обучающей и тестовой выборках, и построения матрицы ошибок.
-   **`make_confusion_matrix(...)`:** Функция для визуализации матрицы ошибок.

## 4. Краткий EDA (Исследовательский анализ данных)

-   **Загрузка данных:**
    -   `df_train` и `df_test` загружены в pandas DataFrame.
    -   Размерность `df_train`: (105565, 21) - исходная. После разделения на X_train и X_val: X_train (84452, 20), X_val (21113, 20).
    -   Размерность `df_test`: (14261, 21).
-   **Дисбаланс классов:**
    -   Целевая переменная `target` сильно несбалансирована.
    -   Класс 0 (не фрод): 92211 записей.
    -   Класс 1 (фрод): 13354 записи.
    -   Соотношение примерно 7:1.
-   **Описание признаков:**
    -   Датасет содержит информацию о пользователях (`user_id`), товарах (`nm_id`), заказах (`total_ordered`, `PaymentType`, `IsPaid`, `count_items`, `unique_items`), доставке (`is_courier`, `Distance`), активности пользователя (`DaysAfterRegistration`, `number_of_orders`) и агрегированные статистики по заказам.
    -   `service` - тип региона.
    -   `NmAge` - возраст товара.
-   **Корреляция признаков:**
    -   Построена тепловая карта корреляций числовых признаков. В результате было принято решение удалить из процесса обучения `min_number_of_ordered_items` и `max_number_of_ordered_items` т.к. он сильно коррелирует с `mean_number_of_ordered_items`.

## 5. Построение Pipeline и Обучение Модели

### 5.1. Разделение данных

-   Данные `df_train` были разделены на признаки (`X`) и целевую переменную (`y`).
-   Затем `X` и `y` были разделены на обучающую (`X_train`, `y_train`) и валидационную (`X_val`, `y_val`) выборки в соотношении 80/20.
-   Датасет `df_test` использовался как полный тестовый набор (`X_test_full`, `y_test_full`).

### 5.2. Инженерия признаков (включена в пайплайн)

-   **`MultiplyColumns`**:
    -   Создан признак `count_to_unique` = `count_items` * `unique_items`.
-   **`DivideColumns`**:
    -   Создан признак `uni_div_days` = `unique_items` / `DaysAfterRegistration`.
    -   Создан признак `days_div_orders` = `DaysAfterRegistration` / `number_of_orders`.
-   В процессе работы были протестированы различные варианты перемножения/деления данных и создания новых признаков, но в итоговый пайплайн попали только эти.

### 5.3. Предобработка признаков (включена в пайплайн)

Признаки были разделены на три группы:

-   **`numerical_features`** (13 признаков, включая созданные `uni_div_days` и `days_div_orders`):
    -   Заполнение пропусков медианой (`SimpleImputer`).
    -   Масштабирование с помощью `MinMaxScaler`.
-   **`categorical_features`** (`PaymentType`, `IsPaid`, `service`):
    -   Заполнение пропусков наиболее частым значением (`SimpleImputer`).
    -   Кодирование с помощью `OneHotEncoder` (неизвестные значения игнорируются).
-   **`binning_features`** (трансформер для них определен, в ходе тестирования разделение данных на бины не дало улучшения):
    -   Заполнение пропусков медианой (`SimpleImputer`).
    -   Дискретизация на 5 бинов с помощью `KBinsDiscretizer` (стратегия `uniform`, кодирование `ordinal`).

Преобразования для разных типов признаков были объединены с помощью `ColumnTransformer`.

### 5.4. Борьба с дисбалансом классов (включена в пайплайн)

-   Использовался метод `SMOTE` (Synthetic Minority Over-sampling Technique) для увеличения представленности миноритарного класса.

### 5.5. Модель

-   В качестве классификатора использовался `RandomForestClassifier`.
-   Кроме того тестировались: `CatBoost`, `LGBMClassifier`, `XGBoostClassifier`, по результатам тестов выбор был сделан в пользу `RandomForestClassifier`.

### 5.6. Финальный пайплайн (`pipe_1`)

Пайплайн состоит из следующих шагов:
1.  `multiply_columns`: Создание признака путем умножения.
2.  `divide_columns`: Создание признаков путем деления.
3.  `preprocessing`: Применение `ColumnTransformer` для числовых, категориальных и биннинговых признаков.
4.  `smote`: Применение SMOTE для балансировки классов.
5.  `estimator`: Модель `RandomForestClassifier`.

### 5.7. Подбор гиперпараметров и оценка на валидационной выборке

-   Для `RandomForestClassifier` были заданы следующие "оптимальные" параметры (через `rf_params_grid`, хотя сетка содержит только одно значение для каждого параметра, в ходе тестов проверлись списки вариантов):
    -   `class_weight`: 'balanced'
    -   `max_depth`: 7
    -   `min_samples_leaf`: 3
    -   `n_estimators`: 100
    -   `random_state`: SEED (42)
-   Пайплайн обучался на `X_train`, `y_train` и оценивался на `X_val`, `y_val`.
-   **Результаты на валидации:**
    -   F1\_train: 0.6741
    -   F1\_val: 0.6782
    -   Distance: -0.61% (небольшое различие, модель не перобучилась)
    -   Матрица ошибок для валидационной выборки:
        -   TN: 15780, FP: 2647
        -   FN: 874, TP: 1812
![Матрица ошибок Валидация](cm1.jpg "Матрица ошибок Валидация")

## 6. Обучение на полных тренировочных данных и оценка на тестовых данных

### 6.1. Обучение

-   Модель `pipe_1_model_final` была обучена на всем датасете `df_train` (признаки `X`, цель `y`) с использованием тех же "лучших" параметров.
-   F1\_train (на полных данных): 0.6641 (Результат близкий к предыдущему)

### 6.2. Предсказания на тестовых данных (`df_test`)

-   Предсказания были сделаны на `X_test_full`, `y_test_full`.
-   **Финальный F1-score на тестовых данных: 0.3319**
-   Матрица ошибок для тестовой выборки:
    -   TN: 6894, FP: 5322
    -   FN: 1012, TP: 1033
-   Данные тестового датафрейма несколько отличаются от данных Трейн.
![Матрица ошибок Тест](cm2.jpg "Матрица ошибок Тест")

## 7. Сохранение модели

-   Обученная модель `pipe_1_model_final` была сохранена в файл `pipe_1_model_final.joblib` с помощью `joblib.dump`.

## 8. Ключевые выводы

-   Проект успешно реализовал пайплайн для детекции фрода, включающий инженерию признаков, предобработку, балансировку классов и обучение модели RandomForest.
-   На валидационной выборке (части `df_train`) модель показала F1-меру 0.6782.
-   **На предоставленном тестовом датасете (`df_test`) финальная F1-мера составила 0.3319.**
-   Существует значительное расхождение в производительности модели между валидационной выборкой (сформированной из `df_train`) и тестовой выборкой (`df_test`). Это может указывать на то, что:
    -   Тестовая выборка имеет отличное от тренировочной распределение данных.
    -   Параметры, подобранные на валидационной части `df_train`, не являются оптимальными для `df_test`.
